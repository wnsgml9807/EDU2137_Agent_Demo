import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage # AIMessageChunk ì œê±°
from langchain.memory import ConversationBufferMemory # ë©”ëª¨ë¦¬ ì¶”ê°€
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # í”„ë¡¬í”„íŠ¸ ì¶”ê°€
from langchain.chains import LLMChain # LLMChain ì¶”ê°€
import json
import uuid # uuid ì„í¬íŠ¸
import sys
import os
import asyncio
import re # í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìœ„í•´ ì¶”ê°€
from dotenv import load_dotenv # dotenv ì„í¬íŠ¸
import time # time ëª¨ë“ˆ ì¶”ê°€

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# tools.py ê²½ë¡œ ì„¤ì • (ë‹¤ì‹œ ì¶”ê°€)
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)
# Agentìš© @tool í•¨ìˆ˜ ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜ìš© ì¼ë°˜ í•¨ìˆ˜ ì„í¬íŠ¸
from tools import get_seoul_weather_data, get_picnic_restaurant_data

# --- LLM ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
try:
    anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
    if not anthropic_api_key:
        anthropic_api_key = st.secrets["ANTHROPIC_API_KEY"]
        print("ì ‘ê·¼ ì„±ê³µ")  
    if not anthropic_api_key:
        raise ValueError("ANTHROPIC_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” secrets.tomlì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    from langchain_anthropic import ChatAnthropic
    llm = ChatAnthropic(
        model="claude-3-5-sonnet-latest",
        temperature=0.7,
        api_key=anthropic_api_key
    )
except ValueError as e:
    print("ì ‘ê·¼ ì‹¤íŒ¨")
    st.error(e)
    st.stop()
except Exception as e:
    st.error(f"LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    st.stop()

# --- í”„ë¡¬í”„íŠ¸ ë° ë©”ëª¨ë¦¬ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
# í˜ì´ì§€ë³„ ê³ ìœ  ë©”ëª¨ë¦¬ í‚¤
MEMORY_KEY = "explicit_memory"
if MEMORY_KEY not in st.session_state:
    st.session_state[MEMORY_KEY] = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

memory = st.session_state[MEMORY_KEY]

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì‚¬ì´ë“œë°”ë‚˜ ë²„íŠ¼ ì–¸ê¸‰ ì œê±°)
system_prompt_manual_tools = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í”¼í¬ë‹‰ ê³„íšì„ ë•ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
**ë‹¹ì‹ ì€ ìŠ¤ìŠ¤ë¡œ í˜„ì¬ ë‚ ì”¨ë‚˜ ì‹¤ì‹œê°„ ë§›ì§‘ ì •ë³´ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ì§ í•™ìŠµëœ ì§€ì‹ê³¼ ëŒ€í™” ê¸°ë¡ì—ë§Œ ì˜ì¡´í•©ë‹ˆë‹¤.**
**[ì‘ë‹µ ê·œì¹™]**
1. ë§Œì•½ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ í•¨ê»˜ ì¶”ê°€ ì •ë³´(`[ë‚ ì”¨ ì •ë³´ (ì„œìš¸)]` ë˜ëŠ” `[ë§›ì§‘ ì •ë³´ (í”¼í¬ë‹‰ ìŒì‹)]`)ê°€ ì£¼ì–´ì§„ë‹¤ë©´, **ë°˜ë“œì‹œ ê·¸ ì •ë³´ë¥¼ ë‹µë³€ì— í™œìš©**í•˜ì„¸ìš”.
2. ë§Œì•½ ì¶”ê°€ ì •ë³´ê°€ ì£¼ì–´ì§€ì§€ ì•Šì•˜ë‹¤ë©´, **ë‹¹ì‹ ì€ ìµœì‹  ì •ë³´ë¥¼ ëª¨ë¥¸ë‹¤ëŠ” ì ì„ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ ì¸ì§€**ì‹œí‚¤ê³ , í•™ìŠµëœ ì§€ì‹ê³¼ ëŒ€í™” ê¸°ë¡ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ì´ ê²½ìš°, ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì—ëŠ” ë‹µí•  ìˆ˜ ì—†ë‹¤ê³  ì†”ì§í•˜ê²Œ ë§í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
3. ì¶œë ¥ì€ ì´ëª¨ì§€ì™€ ë§ˆí¬ë‹¤ìš´ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.
"""

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (MessagesPlaceholder ì‚¬ìš©)
prompt_template = ChatPromptTemplate.from_messages(
    [
        ("system", system_prompt_manual_tools),
        MessagesPlaceholder(variable_name="chat_history"), # ë©”ëª¨ë¦¬
        ("human", "{input}"), # ì‚¬ìš©ìì˜ ìµœì¢… ì…ë ¥ (ì§ˆë¬¸ + ë„êµ¬ ê²°ê³¼ í¬í•¨ ê°€ëŠ¥)
    ]
)

# LLMChain ìƒì„±
chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)


# --- Streamlit UI ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼) ---
st.title("RAG ChatbotğŸ”§")
st.write("""
í”„ë¡¬í”„íŠ¸ ì…ë ¥ ì‹œ ì¶”ê°€ì ì¸ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n
**ì‚¬ì´ë“œë°”ì˜ í† ê¸€ ë²„íŠ¼**ì„ ì´ìš©í•´ ë¯¸ë¦¬ ì¤€ë¹„ëœ ì •ë³´ë¥¼ ì§ˆë¬¸ì— ì²¨ë¶€í•´ ë³´ì„¸ìš”.""")

# --- ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ (í‘œì‹œìš© ë¦¬ìŠ¤íŠ¸ ì¶”ê°€) ---
DISPLAY_MESSAGES_KEY = "explicit_display_messages_v6"
if DISPLAY_MESSAGES_KEY not in st.session_state:
    st.session_state[DISPLAY_MESSAGES_KEY] = []

# --- íƒ€ì´í•‘ íš¨ê³¼ ì œë„ˆë ˆì´í„° --- 
def typing_effect_generator(text: str, speed: float = 0.01):
    for char in text:
        yield char
        time.sleep(speed)

# --- ë Œë”ë§ í•¨ìˆ˜ ì •ì˜ (ìˆ˜ì •) ---
def render_message_data(msg_data):
    role = msg_data.get("role")
    content = msg_data.get("content")
    name = msg_data.get("name")

    if role == "user":
        with st.chat_message("user"):
            st.markdown(content)
    elif role == "assistant":
        # ì €ì¥ëœ ê¸°ë¡ì€ í•­ìƒ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í‘œì‹œ
        with st.chat_message("assistant"):
            if content:
                 st.markdown(content)
    elif role == "tool_result": 
         with st.expander(f"ì²¨ë¶€ëœ {name} ì •ë³´", expanded=True):
              is_restaurant_tool = name and ("ë§›ì§‘" in name or "restaurant" in name.lower())
              try:
                  parsed_content = json.loads(content) if isinstance(content, str) else content
                  if is_restaurant_tool and isinstance(parsed_content, list):
                       st.dataframe(parsed_content)
                  else:
                      st.code(json.dumps(parsed_content, indent=2, ensure_ascii=False, default=str), language='json')
              except (json.JSONDecodeError, TypeError):
                  st.code(str(content), language='text')

# --- ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ ---
for msg_data in st.session_state[DISPLAY_MESSAGES_KEY]:
    render_message_data(msg_data)

# --- ë„êµ¬ í™œì„±í™” ë²„íŠ¼ (ì‚¬ì´ë“œë°”) ---
with st.sidebar:
    st.header("ë„êµ¬ ì˜µì…˜")
    if 'activate_weather' not in st.session_state:
        st.session_state.activate_weather = False
    st.session_state.activate_weather = st.toggle("ì„œìš¸ ë‚ ì”¨ í™•ì¸", value=st.session_state.activate_weather, key="weather_toggle", help="í™œì„±í™”í•˜ê³  ì§ˆë¬¸í•˜ë©´ ë¯¸ë¦¬ ì¤€ë¹„ëœ ì„œìš¸ ë‚ ì”¨ ì •ë³´ë¥¼ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.")

    if 'activate_restaurants' not in st.session_state:
        st.session_state.activate_restaurants = False
    st.session_state.activate_restaurants = st.toggle("ë§›ì§‘ ê²€ìƒ‰", value=st.session_state.activate_restaurants, key="resto_toggle", help="í™œì„±í™”í•˜ê³  ì§ˆë¬¸í•˜ë©´ ë¯¸ë¦¬ ì¤€ë¹„ëœ 'í”¼í¬ë‹‰ ìŒì‹' ë§›ì§‘ ì •ë³´ë¥¼ í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.")

# --- ì‚¬ìš©ì ì…ë ¥ ë° AI ì‘ë‹µ ì²˜ë¦¬ (ì¦‰ì‹œ ë Œë”ë§) ---
if prompt := st.chat_input("ë‚´ì¼ ì‹ ì´Œì—ì„œ í”¼í¬ë‹‰ì„ í•  ê³„íšì´ì•¼. ë‚ ì”¨ì™€ ë§›ì§‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„íšì„ ì„¸ì›Œì¤˜."):
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¦‰ì‹œ ë Œë”ë§
    user_msg = {"role": "user", "content": prompt}
    st.session_state[DISPLAY_MESSAGES_KEY].append(user_msg)
    render_message_data(user_msg)

    tool_results_text = "" # LLM ì…ë ¥ìš©

    # 2. í™œì„±í™”ëœ ë„êµ¬ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥/ì¦‰ì‹œ ë Œë”ë§
    if st.session_state.activate_weather:
        try:
            weather_result = get_seoul_weather_data()
            result_str = json.dumps(weather_result, ensure_ascii=False)
            tool_results_text += f"\n\n[ë‚ ì”¨ ì •ë³´ (ì„œìš¸)]\n{result_str}"
            tool_data = {"role": "tool_result", "name": "ë‚ ì”¨ (ì„œìš¸)", "content": result_str}
            st.session_state[DISPLAY_MESSAGES_KEY].append(tool_data)
            render_message_data(tool_data) # ë„êµ¬ ê²°ê³¼ ì¦‰ì‹œ ë Œë”ë§
        except Exception as e:
            st.error(f"ë‚ ì”¨ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}") 
        st.session_state.activate_weather = False

    if st.session_state.activate_restaurants:
        try:
             resto_result = get_picnic_restaurant_data()
             result_str = json.dumps(resto_result, indent=2, ensure_ascii=False)
             tool_results_text += f"\n\n[ë§›ì§‘ ì •ë³´ (í”¼í¬ë‹‰ ìŒì‹)]\n{result_str}"
             tool_data = {"role": "tool_result", "name": "ë§›ì§‘ (í”¼í¬ë‹‰ ìŒì‹)", "content": result_str}
             st.session_state[DISPLAY_MESSAGES_KEY].append(tool_data)
             render_message_data(tool_data) # ë„êµ¬ ê²°ê³¼ ì¦‰ì‹œ ë Œë”ë§
        except Exception as e:
            st.error(f"ë§›ì§‘ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        st.session_state.activate_restaurants = False

    # 3. LLM ì…ë ¥ êµ¬ì„± ë° ì‘ë‹µ ìƒì„±/ë Œë”ë§/ì €ì¥
    final_input_for_llm = prompt + tool_results_text
    # ë©”ëª¨ë¦¬ ìë™ ì¶”ê°€ë¨ (invoke ì‚¬ìš© ì‹œ)
    with st.chat_message("assistant"):
            try:
                # invokeë¡œ ì „ì²´ ì‘ë‹µ ë°›ê¸°
                response = chain.invoke({"input": final_input_for_llm})
                final_response_content = response.get('text', response.get('response', "ì‘ë‹µ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))
                if not isinstance(final_response_content, str): final_response_content = str(final_response_content)
                
                if final_response_content:
                     # íƒ€ì´í•‘ íš¨ê³¼ë¡œ ì¦‰ì‹œ ë Œë”ë§
                     displayed_response = st.write_stream(typing_effect_generator(final_response_content))
                     # ìµœì¢… ë‚´ìš© ì €ì¥
                     st.session_state[DISPLAY_MESSAGES_KEY].append({"role": "assistant", "content": displayed_response})
                     # ë©”ëª¨ë¦¬ ìë™ ì¶”ê°€
            
            except Exception as e:
                 error_message = f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
                 st.error(error_message) 
                 st.session_state[DISPLAY_MESSAGES_KEY].append({"role": "assistant", "content": error_message})
