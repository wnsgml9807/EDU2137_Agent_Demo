import streamlit as st
from langchain_anthropic import ChatAnthropic # ë˜ëŠ” ë‹¤ë¥¸ ChatModel
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage # í•„ìš”í•œ ë©”ì‹œì§€ íƒ€ì… ë‹¤ì‹œ ì„í¬íŠ¸
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
import json
import uuid # uuid ì„í¬íŠ¸
import sys
import os
import asyncio # ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¶”ê°€
import dotenv
import time # time ëª¨ë“ˆ ì¶”ê°€

dotenv.load_dotenv()

anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
if not anthropic_api_key:
    anthropic_api_key = st.secrets.get("ANTHROPIC_API_KEY")

# tools.py ê²½ë¡œ ì„¤ì • (í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ìƒìœ„ í´ë”)
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)
from tools import get_weather, search_restaurants

# --- LLM ë° ë„êµ¬ ì„¤ì • --- 
# API í‚¤ ì„¤ì • (st.secrets ì‚¬ìš© ê¶Œì¥)
try:
    llm = ChatAnthropic(model="claude-3-5-sonnet-latest", temperature=0.7, api_key=anthropic_api_key)
except Exception as e:
    st.error(f"LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}. API í‚¤ë¥¼ Streamlit secretsì— ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

tools = [get_weather, search_restaurants]

# --- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ --- 
system_prompt_template_react = """
ë‹¹ì‹ ì€ í”¼í¬ë‹‰ ì¤€ë¹„ë¼ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ í†µí•´, AI ì—ì´ì „íŠ¸ì˜ ì‘ë™ ê³¼ì •ì„ ë³´ì—¬ ì¤˜ì•¼ í•©ë‹ˆë‹¤.
1. ì‚¬ìš©ìê°€ ìš”ì²­ì„ ì…ë ¥í•˜ë©´, ë¨¼ì € êµ¬ì²´ì ì¸ ë„êµ¬ í™œìš© ê³„íšì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.
2. ê·¸ë¦¬ê³  ì´í›„ì—ëŠ” ê³„íšì„ ì‹¤í–‰í•´ ê°€ëŠ” ê³¼ì •ì„ ë³´ì—¬ ì£¼ì„¸ìš”. 
ì¶œë ¥ì€ ì´ëª¨ì§€ì™€ ë§ˆí¬ë‹¤ìš´ì„ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ì‰½ê²Œ ì½ì„ ìˆ˜ ìˆë„ë¡ í•´ ì£¼ì„¸ìš”.
ì£¼ì–´ì§„ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´, ë‹¹ì‹ ì€ ë‹¤ìŒ ë„êµ¬ë“¤ì„ **ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ ì ê·¹ì ìœ¼ë¡œ í™œìš©**í•´ì•¼ í•©ë‹ˆë‹¤:
- `get_weather`: íŠ¹ì • ì¥ì†Œì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì–»ìŠµë‹ˆë‹¤. (ì˜ˆ: í”¼í¬ë‹‰ ë‹¹ì¼ ë‚ ì”¨ í™•ì¸)
- `search_restaurants`: ì£¼ë³€ ë§›ì§‘ì´ë‚˜ íŠ¹ì • ì¢…ë¥˜ì˜ ì‹ë‹¹ ì •ë³´ë¥¼ ì–»ìŠµë‹ˆë‹¤. (ì˜ˆ: í”¼í¬ë‹‰ ìŒì‹ í¬ì¥ ë˜ëŠ” ì£¼ë³€ ì‹ë‹¹ ê²€ìƒ‰)
"""

# LangGraph ì—ì´ì „íŠ¸ ìƒì„±
try:
    # prompt = ChatPromptTemplate.from_messages(...) # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì •ì˜ëŠ” create_react_agent ë‚´ë¶€ ë¡œì§ê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì œê±°í•©ë‹ˆë‹¤.
    
    # í˜ì´ì§€ë³„ ë©”ëª¨ë¦¬ ê´€ë¦¬
    if 'memory_react' not in st.session_state:
        st.session_state.memory_react = MemorySaver()
    memory = st.session_state.memory_react

    # create_react_agent í˜¸ì¶œ ì‹œ system_message ì¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í™•í•˜ê²Œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
    agent_executor = create_react_agent(
        llm, 
        tools, 
        prompt=system_prompt_template_react,
        checkpointer=memory
    )
except Exception as e:
    st.error(f"ì—ì´ì „íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
    st.stop()

# --- Streamlit UI ì„¤ì • --- 
st.title("AI Agent ğŸ¤–")
st.write("""
AI ì—ì´ì „íŠ¸ê°€ ìŠ¤ìŠ¤ë¡œ **ë„êµ¬ë¥¼ ì¸ì§€í•˜ê³  í™œìš©**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n 
ì—ì´ì „íŠ¸ì—ê²Œ ìš”ì²­ì„ ë¶€ì—¬í•˜ê³  ì‘ë™ ê³¼ì •ì„ ê´€ì°°í•´ë³´ì„¸ìš”.""")

# --- ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ (í‘œì‹œìš© ë¦¬ìŠ¤íŠ¸ ì¶”ê°€, checkpointerì™€ ë³„ê°œ) ---
DISPLAY_MESSAGES_KEY = "react_display_messages_v4"
if DISPLAY_MESSAGES_KEY not in st.session_state:
    st.session_state[DISPLAY_MESSAGES_KEY] = []

# --- ìŠ¤ë ˆë“œ ID ê´€ë¦¬ (ê¸°ì¡´ê³¼ ë™ì¼) --- 
THREAD_ID_KEY = "react_agent_thread_id_v2"
if THREAD_ID_KEY not in st.session_state:
    st.session_state[THREAD_ID_KEY] = f"react_thread_{uuid.uuid4()}"

config = {"configurable": {"thread_id": st.session_state[THREAD_ID_KEY]}}

# --- íƒ€ì´í•‘ íš¨ê³¼ ì œë„ˆë ˆì´í„° --- 
def typing_effect_generator(text: str, speed: float = 0.01):
    for char in text:
        yield char
        time.sleep(speed)

# --- ë Œë”ë§ í•¨ìˆ˜ ì •ì˜ (ìˆ˜ì •) ---
def render_message_data(msg_data, is_new=False):
    role = msg_data.get("role") or msg_data.get("type")
    content = msg_data.get("content") or msg_data.get("text")
    name = msg_data.get("name") or msg_data.get("tool_name")
    tool_input = msg_data.get("input")

    if role == "user":
        with st.chat_message("user"):
            st.markdown(content)
    elif role == "assistant": # ì €ì¥ëœ assistant í„´ ë Œë”ë§ (is_new=False)
        with st.chat_message("assistant"):
            if isinstance(content, list):
                for item in content:
                    render_message_data(item, is_new=False) # í•˜ìœ„ í•­ëª© ë Œë”ë§
            elif content:
                 st.markdown(content) # ë‹¨ìˆœ ë¬¸ìì—´ content ê²½ìš°
                 
    elif role == "ai": # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ AI í…ìŠ¤íŠ¸ ì²­í¬ (is_new=True)
        # ì´ë¯¸ chat_message("assistant") ì»¨í…ìŠ¤íŠ¸ ì•ˆì— ìˆìŒ
        if content:
             # is_newê°€ Trueì¼ ë•Œë§Œ íƒ€ì´í•‘ íš¨ê³¼ ì ìš©
             if is_new:
                 st.write_stream(typing_effect_generator(content))
             else: # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì¶”ê°€ (ë³´í†µ ì €ì¥ëœ ê¸°ë¡ì€ assistant roleë¡œ)
                 st.markdown(content)
                 
    elif role == "tool_start":
         st.info(f"ğŸ› ï¸ **{name or '?'}** ë„êµ¬ í˜¸ì¶œ ì¤‘...", icon="ğŸ”„")
         if tool_input:
             with st.expander("ë„êµ¬ ì…ë ¥ ë³´ê¸°", expanded=False):
                try:
                    st.code(json.dumps(tool_input, indent=2, ensure_ascii=False), language="json")
                except Exception:
                    st.code(str(tool_input), language='text')
    elif role == "tool_end":
         # ë§›ì§‘ ê²€ìƒ‰ ê²°ê³¼ì¸ì§€ í™•ì¸
         is_restaurant_tool = name and ("ë§›ì§‘" in name or "restaurant" in name.lower())
         
         try:
             # contentê°€ ë¬¸ìì—´ì´ë©´ JSON íŒŒì‹± ì‹œë„, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
             parsed_output = json.loads(content) if isinstance(content, str) else content
             
             # ë§›ì§‘ ê²€ìƒ‰ ê²°ê³¼ì´ê³ , íŒŒì‹± ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ë©´ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í‘œì‹œ
             if is_restaurant_tool and isinstance(parsed_output, list):
                  st.dataframe(parsed_output)
             else:
                  # ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” JSON ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ í‘œì‹œ
                  st.code(json.dumps(parsed_output, indent=2, ensure_ascii=False, default=str), language='json')
                  
         except (json.JSONDecodeError, TypeError):
             # íŒŒì‹± ì‹¤íŒ¨í•˜ê±°ë‚˜ JSON ë³€í™˜ ë¶ˆê°€ ì‹œ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
             st.code(str(content), language=None)
    elif role == "error":
         st.error(content)

# --- ì´ì „ ëŒ€í™” ê¸°ë¡ í‘œì‹œ (í‘œì‹œìš© ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©) ---
for msg_data in st.session_state[DISPLAY_MESSAGES_KEY]:
    # ì €ì¥ëœ ê° í„´(user ë˜ëŠ” assistant) ë Œë”ë§
    render_message_data(msg_data, is_new=False)

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ --- 
if prompt := st.chat_input("ë‚´ì¼ ì‹ ì´Œì—ì„œ í”¼í¬ë‹‰ì„ í•  ê³„íšì´ì•¼. ë‚ ì”¨ì™€ ë§›ì§‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê³„íšì„ ì„¸ì›Œì¤˜"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¦‰ì‹œ ë Œë”ë§
    user_msg = {"role": "user", "content": prompt, "id": f"user_{uuid.uuid4()}"}
    st.session_state[DISPLAY_MESSAGES_KEY].append(user_msg)
    render_message_data(user_msg)
    # Checkpointerê°€ ë©”ëª¨ë¦¬ì— HumanMessage ì¶”ê°€

    # --- AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° (astream + ì¦‰ì‹œ ë Œë”ë§, ì™„ë£Œ í›„ ì €ì¥) ---
    with st.chat_message("assistant"): # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸
        current_turn_messages = [] # ì´ë²ˆ í„´ ë Œë”ë§ ë°ì´í„° ìˆ˜ì§‘

        async def stream_and_render_chunks():
            # ì²­í¬ ë¶„ì„ ë° ë Œë”ë§ ë°ì´í„° ìƒì„± í•¨ìˆ˜
            def get_render_data_from_chunk(chunk):
                render_data_list = []
                if isinstance(chunk, dict):
                    if agent_messages := chunk.get("agent", {}).get("messages", []):
                        msg = agent_messages[-1]
                        if isinstance(msg, AIMessage):
                            content_val = msg.content
                            ai_text_content = ""
                            if isinstance(content_val, str): ai_text_content = content_val
                            elif isinstance(content_val, list): texts = [p.get('text', '') for p in content_val if isinstance(p, dict) and p.get('type') == 'text']; ai_text_content = "".join(texts)
                            else: ai_text_content = str(content_val)
                            
                            # í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ìˆìœ¼ë©´ ai íƒ€ì… ë°ì´í„° ì¶”ê°€
                            if ai_text_content:
                                render_data_list.append({"type": "ai", "content": ai_text_content})
                                
                            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆìœ¼ë©´ tool_start íƒ€ì… ë°ì´í„° ì¶”ê°€
                            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                tool_call = msg.tool_calls[0]
                                render_data_list.append({"type": "tool_start", "name": tool_call.get('name'), "input": tool_call.get('args')})
                                
                    elif tool_messages := chunk.get("tools", {}).get("messages", []):
                        msg = tool_messages[-1]
                        if isinstance(msg, ToolMessage):
                            # tool_end íƒ€ì… ë°ì´í„° ì¶”ê°€
                            render_data_list.append({"type": "tool_end", "name": msg.name, "content": msg.content})
                return render_data_list

            # --- astream ë£¨í”„ --- 
            try:
                async for chunk in agent_executor.astream({"messages": [HumanMessage(content=prompt)]}, config=config, stream_mode="updates"):
                    # --- ìˆ˜ì‹ ëœ ì²­í¬ë¥¼ ì½˜ì†”ì— ì¶œë ¥ (ë””ë²„ê¹…ìš© ìœ ì§€) --- 
                    print("\n--- Raw Chunk Received ---")
                    print(chunk)
                    print("--------------------------\n")
                    # --------------------------------
                    
                    render_data_list = get_render_data_from_chunk(chunk)
                    for data_to_render in render_data_list:
                        if data_to_render: 
                            # is_new=True ì „ë‹¬í•˜ì—¬ íƒ€ì´í•‘ íš¨ê³¼ ì ìš©
                            render_message_data(data_to_render, is_new=True) # ì¦‰ì‹œ ë Œë”ë§
                            current_turn_messages.append(data_to_render) # í„´ ê¸°ë¡ì— ì¶”ê°€
                            
            except Exception as e:
                error_data = {"type": "error", "content": f"Agent ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
                render_message_data(error_data, is_new=True) # ì˜¤ë¥˜ ì¦‰ì‹œ ë Œë”ë§
                current_turn_messages.append(error_data) # ì˜¤ë¥˜ë„ í„´ ê¸°ë¡ì— ì¶”ê°€
            
            # ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ í›„ ì „ì²´ í„´ ê¸°ë¡ì„ ì„¸ì…˜ì— ì €ì¥
            if current_turn_messages:
                 st.session_state[DISPLAY_MESSAGES_KEY].append({"role": "assistant", "content": current_turn_messages, "id": f"assistant_{uuid.uuid4()}"})

        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        asyncio.run(stream_and_render_chunks())

    # rerun ì œê±°
